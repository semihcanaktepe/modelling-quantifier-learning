// The body of the model

// OPERATORS

// Binary operator functions for the quantifier rules.

var greater = {fn: function(a,b){return a > b}, expr: ">"}
var less = {fn: function(a,b){return a < b}, expr: "<"}
var equal = {fn: function(a,b){return a == b}, expr: "="}
var greaterorequal = {fn: function(a,b){return a >= b}, expr: ">="}
var lessorequal = {fn: function(a,b){return a <= b}, expr: "<="}
var and = {fn: function(a,b){return a && b}, expr: " & "}
var or = {fn: function(a,b){return a || b}, expr: " | "}

var operators = [greater, less, equal, greaterorequal, lessorequal]

var connectors = [and, or]
// To avoid such situations as bg & gb, and & or connectors are seperated to be
// used in another function where the rules are combined using and & or.

//

// COMBINERS, CONNECTORS AND GENERATORS 

var randomSetFunction = function(event,quan){
  // This function introduces the sets and points to the cardinality of the sets.  
  // Sets respectively refer to "G∩B", "G\B", "B\G", and "U\(G∪B)".
  var set = sample(Categorical({vs:(quan == "conservative") ? ["gb", "gg"] : ["bb", "bg"], ps:dirichlet(Vector([1,1]))}))
  return {fn: function(event){return event[set]},
          expr: set}
}

var randomElementFunction = function(event){
  // This functions introduces the number of elements. Since the maximum number of elements
  // in the experiment is three, the range of the function would be limited to three. However,
  // for such quantifiers as at most three which can be expressed as either smaller than or
  // equal to three or as smaller than four. Therefore, four is also added.
  var c = uniformDraw([0,1,2,3,4])
  return {fn: function(event){return c}, expr: c}
}

var setCombinator = function(f,g){
  // This function combines two sets using their
  // cardinalities and comparison operators.
  var operator = uniformDraw(operators)
  var operatorFn = operator.fn
  var ffn = f.fn
  var gfn = g.fn
  return {fn: function(x){return operatorFn(ffn(x), gfn(x))},
         expr: "("+f.expr+operator.expr+g.expr+")"}
}

var ruleConnector = function(f,g){
  // This function merges two rules for a quantifier
  // by using connector operators "and" & "or".
  var connector = uniformDraw(connectors)
  var connectorFn = connector.fn
  var ffn = f.fn
  var gfn = g.fn
  return {fn: function(x){return connectorFn(ffn(x),gfn(x))},
         expr: "("+f.expr+connector.expr+g.expr+")"}
}

// Rule Generator Function
// This function generates the rules that possibly produce the events for the given quantifier.

var ruleGenerator = function(event,quan){
  var cons = (quan == "conservative") ?
    "conservative" : (quan == "non-conservative") ?
      "non-conservative" : sample(Categorical({vs:["conservative", "non-conservative"], ps:dirichlet(Vector([9,1]))}))
  // It favours the conservative relations.
  return (cons == "conservative") ?
    (flip() ?
      setCombinator(randomSetFunction(event,"conservative"), randomElementFunction(event)) : flip() ?
      setCombinator(randomSetFunction(event,"conservative"), randomSetFunction(event,"conservative")) : ruleConnector(ruleGenerator(event,"conservative"), ruleGenerator(event,"conservative"))) :
    (flip() ?
      setCombinator(randomSetFunction(event,"non-conservative"), randomElementFunction(event)) : flip() ?
      setCombinator(randomSetFunction(event,"conservative"), randomSetFunction(event,"non-conservative")) : flip() ?
      setCombinator(randomSetFunction(event,"non-conservative"), randomSetFunction(event,"non-conservative")) : flip() ?
      ruleConnector(ruleGenerator(event,"conservative"), ruleGenerator(event,"non-conservative")) : flip() ?
      ruleConnector(ruleGenerator(event,"non-conservative"), ruleGenerator(event,"non-conservative")) : ruleConnector(ruleGenerator(event,"non-conservative"), ruleGenerator(event,"conservative")))
}

// RANDOMIZED DATASETS

var ncdata = _.shuffle(nc)
var cdata = _.shuffle(c)
var nldata = _.shuffle(nl)
var eqdata = _.shuffle(eq)

// MODEL'S RESPONSES
// This is where the learning happens. The model takes the first data point in the dataset and generates some set of rules
// from most probable to the least one. Then, it samples one of these rules and applies it to the next data point. For the
// 15th data point, it uses the first 14 cases. Therefore, as more input is provided for the model, it performs better, which
// creates a learning curve for the given quantifier. The first response of the model is always random because no input is
// provided before the model sees the dataset.

var response = function(n){
  sample(Infer({method: "MCMC", kernel: "MH", samples:100, burn:5}, function(){
    var data = // INSERT THE NAME OF THE DATASET HERE!
    var e = ruleGenerator(_.slice(data,0,n),"first")
    var f = e.fn
  
    var ObsFn = function(datum){
      condition(f(datum) == datum.outcome)
    }
    mapData({data:_.slice(data,0,n)}, ObsFn)
    return f(data[n]) == data[n].outcome
  }))
}

var model_correct = function(start,end,arr){
  //start n from 1, k from 79
  var value = response(start)
  return start>end ? error("Start value cannot be greater than End value.") : start==end ?
    arr.concat(value) : model_correct(start+1,end,arr.concat(value))
}

// Here the model is run 20 times. This step functions as if twenty participants took the experiment.
var results = repeat(20, function(){return model_correct(1,79,[flip(0.5)])})

// The results of the simulations are printed.
results
